{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single Rectangle Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Shape: (50000, 8, 8)\n",
      "Bounding Box Shape: (50000, 1, 4)\n"
     ]
    }
   ],
   "source": [
    "# Create images with random rectangles and bounding boxes. \n",
    "num_imgs = 50000\n",
    "\n",
    "img_size = 8\n",
    "min_object_size = 1\n",
    "max_object_size = 4\n",
    "num_objects = 1\n",
    "\n",
    "# create and zero two arrays, one is for the bounding boxes, the other is for the images\n",
    "bboxes = np.zeros((num_imgs, num_objects, 4))\n",
    "# set the pixel value of the background to 0\n",
    "imgs = np.zeros((num_imgs, img_size, img_size))\n",
    "\n",
    "for i_img in range(num_imgs):\n",
    "    for i_object in range(num_objects):\n",
    "        # set the width and height of the rectangle\n",
    "        w, h = np.random.randint(min_object_size, max_object_size, size = 2)\n",
    "        # set the location (x, y) of the rectangle\n",
    "        x = np.random.randint(0, img_size - w)\n",
    "        y = np.random.randint(0, img_size - h)\n",
    "        # set the pixel value of the rectangle to 1\n",
    "        imgs[i_img, x:x + w, y:y + h] = 1.0\n",
    "        bboxes[i_img, i_object] = [x, y, w, h]\n",
    "        \n",
    "print(\"Image Shape: {}\".format(imgs.shape))\n",
    "print(\"Bounding Box Shape: {}\".format(bboxes.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "i = 0\n",
    "# origin: place the [0, 0] index of the array in the upper left or lower left corner of the axes\n",
    "# extent: floats(left, right, bottom, top)\n",
    "plt.imshow(imgs[i].T, cmap = 'Greys', interpolation = 'none', origin = 'lower', extent = [0, img_size, 0, img_size])\n",
    "# tranverse(.T) and flip upside down(origin = 'lower') to fit in the bounding box\n",
    "for bbox in bboxes[i]:\n",
    "    plt.gca().add_patch(matplotlib.patches.Rectangle((bbox[0], bbox[1]), bbox[2], bbox[3], lw = 2, ec = 'r', fc = 'none'))\n",
    "    # patches.Rectangle((x, y), w, h, linewidth, edgecolor, facecolor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((50000, 64), 3.368416656712725e-18, 1.0)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reshape and normalize the image data to mean 0 and std 1. \n",
    "X = (imgs.reshape(num_imgs, -1) - np.mean(imgs)) / np.std(imgs)\n",
    "X.shape, np.mean(X), np.std(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((50000, 4), 0.281453125, 0.17495891747131487)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Normalize x, y, w, h by img_size, so that all values are between 0 and 1.\n",
    "# Important: Do not shift to negative values (e.g. by setting to mean 0), because the IOU calculation needs positive w and h.\n",
    "y = bboxes.reshape(num_imgs, -1) / img_size\n",
    "y.shape, np.mean(y), np.std(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split training and test.\n",
    "i = int(0.8 * num_imgs)\n",
    "train_X, test_X = X[:i], X[i:]\n",
    "train_y ,test_y = y[:i], y[i:]\n",
    "test_imgs = imgs[i:]\n",
    "test_bboxes = bboxes[i:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_2 (Dense)              (None, 200)               13000     \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 4)                 804       \n",
      "=================================================================\n",
      "Total params: 13,804\n",
      "Trainable params: 13,804\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Build the model.\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "model = Sequential([\n",
    "        Dense(200, input_dim = X.shape[-1]),\n",
    "        Activation('relu'), \n",
    "        Dropout(0.2), \n",
    "        Dense(y.shape[-1])\n",
    "        ])\n",
    "model.compile(loss = 'mse', optimizer = 'adam', metrics = ['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1250/1250 [==============================] - 1s 883us/step - loss: 0.0260 - accuracy: 0.7088 - val_loss: 7.8385e-04 - val_accuracy: 0.8944\n",
      "Epoch 2/30\n",
      "1250/1250 [==============================] - 1s 783us/step - loss: 0.0023 - accuracy: 0.8438 - val_loss: 2.9428e-04 - val_accuracy: 0.8753\n",
      "Epoch 3/30\n",
      "1250/1250 [==============================] - 1s 787us/step - loss: 0.0014 - accuracy: 0.8486 - val_loss: 1.6840e-04 - val_accuracy: 0.8721\n",
      "Epoch 4/30\n",
      "1250/1250 [==============================] - 1s 781us/step - loss: 0.0011 - accuracy: 0.8478 - val_loss: 1.6911e-04 - val_accuracy: 0.8322\n",
      "Epoch 5/30\n",
      "1250/1250 [==============================] - 1s 785us/step - loss: 9.4217e-04 - accuracy: 0.8485 - val_loss: 2.1356e-04 - val_accuracy: 0.8855\n",
      "Epoch 6/30\n",
      "1250/1250 [==============================] - 1s 796us/step - loss: 8.4843e-04 - accuracy: 0.8477 - val_loss: 1.7260e-04 - val_accuracy: 0.8604\n",
      "Epoch 7/30\n",
      "1250/1250 [==============================] - 1s 850us/step - loss: 7.9675e-04 - accuracy: 0.8481 - val_loss: 2.1689e-04 - val_accuracy: 0.8247\n",
      "Epoch 8/30\n",
      "1250/1250 [==============================] - 1s 798us/step - loss: 7.5871e-04 - accuracy: 0.8460 - val_loss: 1.5603e-04 - val_accuracy: 0.8957\n",
      "Epoch 9/30\n",
      "1250/1250 [==============================] - 1s 783us/step - loss: 7.2384e-04 - accuracy: 0.8458 - val_loss: 1.4723e-04 - val_accuracy: 0.8149\n",
      "Epoch 10/30\n",
      "1250/1250 [==============================] - 1s 780us/step - loss: 6.9962e-04 - accuracy: 0.8449 - val_loss: 1.8782e-04 - val_accuracy: 0.8821\n",
      "Epoch 11/30\n",
      "1250/1250 [==============================] - 1s 787us/step - loss: 6.7483e-04 - accuracy: 0.8440 - val_loss: 1.6433e-04 - val_accuracy: 0.8681\n",
      "Epoch 12/30\n",
      "1250/1250 [==============================] - 1s 868us/step - loss: 6.6396e-04 - accuracy: 0.8460 - val_loss: 1.3507e-04 - val_accuracy: 0.9025\n",
      "Epoch 13/30\n",
      "1250/1250 [==============================] - 1s 786us/step - loss: 6.4136e-04 - accuracy: 0.8471 - val_loss: 1.5583e-04 - val_accuracy: 0.7690\n",
      "Epoch 14/30\n",
      "1250/1250 [==============================] - 1s 783us/step - loss: 6.4202e-04 - accuracy: 0.8441 - val_loss: 1.8472e-04 - val_accuracy: 0.8455\n",
      "Epoch 15/30\n",
      "1250/1250 [==============================] - 1s 786us/step - loss: 6.3617e-04 - accuracy: 0.8450 - val_loss: 1.4767e-04 - val_accuracy: 0.8408\n",
      "Epoch 16/30\n",
      "1250/1250 [==============================] - 1s 786us/step - loss: 6.2387e-04 - accuracy: 0.8423 - val_loss: 1.2489e-04 - val_accuracy: 0.8794\n",
      "Epoch 17/30\n",
      "1250/1250 [==============================] - 1s 790us/step - loss: 6.2030e-04 - accuracy: 0.8457 - val_loss: 1.2101e-04 - val_accuracy: 0.8418\n",
      "Epoch 18/30\n",
      "1250/1250 [==============================] - 1s 797us/step - loss: 6.1403e-04 - accuracy: 0.8442 - val_loss: 1.3876e-04 - val_accuracy: 0.8647\n",
      "Epoch 19/30\n",
      "1250/1250 [==============================] - 1s 862us/step - loss: 6.1252e-04 - accuracy: 0.8446 - val_loss: 1.5315e-04 - val_accuracy: 0.8532\n",
      "Epoch 20/30\n",
      "1250/1250 [==============================] - 1s 804us/step - loss: 6.0236e-04 - accuracy: 0.8443 - val_loss: 1.5798e-04 - val_accuracy: 0.8758\n",
      "Epoch 21/30\n",
      "1250/1250 [==============================] - 1s 824us/step - loss: 6.0480e-04 - accuracy: 0.8432 - val_loss: 1.4356e-04 - val_accuracy: 0.8213\n",
      "Epoch 22/30\n",
      "1250/1250 [==============================] - 1s 832us/step - loss: 6.0359e-04 - accuracy: 0.8450 - val_loss: 1.5483e-04 - val_accuracy: 0.8857\n",
      "Epoch 23/30\n",
      "1250/1250 [==============================] - 1s 844us/step - loss: 5.9842e-04 - accuracy: 0.8440 - val_loss: 1.1426e-04 - val_accuracy: 0.8725\n",
      "Epoch 24/30\n",
      "1250/1250 [==============================] - 1s 786us/step - loss: 5.9508e-04 - accuracy: 0.8463 - val_loss: 1.1130e-04 - val_accuracy: 0.8416\n",
      "Epoch 25/30\n",
      "1250/1250 [==============================] - 1s 790us/step - loss: 5.8894e-04 - accuracy: 0.8450 - val_loss: 1.5980e-04 - val_accuracy: 0.8763\n",
      "Epoch 26/30\n",
      "1250/1250 [==============================] - 1s 785us/step - loss: 5.8735e-04 - accuracy: 0.8444 - val_loss: 9.0072e-05 - val_accuracy: 0.8562\n",
      "Epoch 27/30\n",
      "1250/1250 [==============================] - 1s 797us/step - loss: 5.9452e-04 - accuracy: 0.8444 - val_loss: 1.4270e-04 - val_accuracy: 0.8320\n",
      "Epoch 28/30\n",
      "1250/1250 [==============================] - 1s 831us/step - loss: 5.9434e-04 - accuracy: 0.8435 - val_loss: 1.5426e-04 - val_accuracy: 0.8295\n",
      "Epoch 29/30\n",
      "1250/1250 [==============================] - 1s 913us/step - loss: 5.8904e-04 - accuracy: 0.8447 - val_loss: 1.4293e-04 - val_accuracy: 0.8209\n",
      "Epoch 30/30\n",
      "1250/1250 [==============================] - 1s 882us/step - loss: 5.8940e-04 - accuracy: 0.8442 - val_loss: 1.1991e-04 - val_accuracy: 0.8594\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1ed4a918820>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train\n",
    "model.fit(train_X, train_y, epochs = 30, validation_data = (test_X, test_y), verbose = 1,\n",
    "          callbacks = [ModelCheckpoint('Single_Rectangle_model.h5',\n",
    "                                       monitor = 'val_accuracy',\n",
    "                                       save_best_only = True)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 1, 4)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predict bounding boxes on the test images.\n",
    "from keras.models import load_model\n",
    "model_test = load_model('Single_Rectangle_model.h5')\n",
    "prediction = model_test.predict(test_X)\n",
    "pred_bboxes = prediction * img_size\n",
    "pred_bboxes = pred_bboxes.reshape(len(pred_bboxes), num_objects, -1)\n",
    "pred_bboxes.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IoU Calculating Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def IOU(bbox1, bbox2):\n",
    "    '''Calculate overlap between two bounding boxes [x, y, w, h] as the area of intersection over the area of unity'''\n",
    "    x1, y1, w1, h1 = bbox1[0], bbox1[1], bbox1[2], bbox1[3]\n",
    "    x2, y2, w2, h2 = bbox2[0], bbox2[1], bbox2[2], bbox2[3]\n",
    "\n",
    "    w_I = min(x1 + w1, x2 + w2) - max(x1, x2)\n",
    "    h_I = min(y1 + h1, y2 + h2) - max(y1, y2)\n",
    "    if w_I <= 0 or h_I <= 0:  # no overlap\n",
    "        return 0.\n",
    "    I = w_I * h_I\n",
    "\n",
    "    U = w1 * h1 + w2 * h2 - I\n",
    "\n",
    "    return I / U"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x216 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Show a few images and predicted bounding boxes from the test dataset. \n",
    "plt.figure(figsize = (12, 3))\n",
    "for i_subplot in range(1, 5):\n",
    "    plt.subplot(1, 4, i_subplot)\n",
    "    i = np.random.randint(len(test_imgs))\n",
    "    plt.imshow(test_imgs[i].T, cmap = 'Greys', interpolation = 'none', origin = 'lower', extent = [0, img_size, 0, img_size])\n",
    "    for pred_bbox, exp_bbox in zip(pred_bboxes[i], test_bboxes[i]):\n",
    "        plt.gca().add_patch(matplotlib.patches.Rectangle((pred_bbox[0], pred_bbox[1]), pred_bbox[2], pred_bbox[3], lw = 2, ec = 'r', fc = 'none'))\n",
    "        plt.annotate(\"IOU: {:.2f}\".format(IOU(pred_bbox, exp_bbox)), (pred_bbox[0], pred_bbox[1] + pred_bbox[3] + 0.2), color = 'r')\n",
    "        # plt.annotate(text, (x, y), color)\n",
    "        \n",
    "plt.savefig(\"single-rectangle_prediction.png\", dpi = 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overall Assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8310774643257784"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate the mean IOU (overlap) between the predicted and expected bounding boxes on the test dataset. \n",
    "summed_IOU = 0.\n",
    "for pred_bbox, test_bbox in zip(pred_bboxes.reshape(-1, 4), test_bboxes.reshape(-1, 4)):\n",
    "    summed_IOU += IOU(pred_bbox, test_bbox)\n",
    "mean_IOU = summed_IOU / len(pred_bboxes)\n",
    "mean_IOU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tensorflow-gpu)",
   "language": "python",
   "name": "tf-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
