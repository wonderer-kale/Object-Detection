{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single Rectangle Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Shape: (50000, 8, 8)\n",
      "Bounding Box Shape: (50000, 1, 4)\n"
     ]
    }
   ],
   "source": [
    "# Create images with random rectangles and bounding boxes. \n",
    "num_imgs = 50000\n",
    "\n",
    "img_size = 8\n",
    "min_object_size = 1\n",
    "max_object_size = 4\n",
    "num_objects = 1\n",
    "\n",
    "# create and zero two arrays, one is for the bounding boxes, the other is for the images\n",
    "bboxes = np.zeros((num_imgs, num_objects, 4))\n",
    "# set the pixel value of the background to 0\n",
    "imgs = np.zeros((num_imgs, img_size, img_size))\n",
    "\n",
    "for i_img in range(num_imgs):\n",
    "    for i_object in range(num_objects):\n",
    "        # set the width and height of the rectangle\n",
    "        w, h = np.random.randint(min_object_size, max_object_size, size = 2)\n",
    "        # set the location (x, y) of the rectangle\n",
    "        x = np.random.randint(0, img_size - w)\n",
    "        y = np.random.randint(0, img_size - h)\n",
    "        # set the pixel value of the rectangle to 1\n",
    "        imgs[i_img, x:x + w, y:y + h] = 1.0\n",
    "        bboxes[i_img, i_object] = [x, y, w, h]\n",
    "        \n",
    "print(\"Image Shape: {}\".format(imgs.shape))\n",
    "print(\"Bounding Box Shape: {}\".format(bboxes.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "i = 0\n",
    "# origin: place the [0, 0] index of the array in the upper left or lower left corner of the axes\n",
    "# extent: floats(left, right, bottom, top)\n",
    "plt.imshow(imgs[i].T, cmap = 'Greys', interpolation = 'none', origin = 'lower', extent = [0, img_size, 0, img_size])\n",
    "# tranverse(.T) and flip upside down(origin = 'lower') to fit in the bounding box\n",
    "for bbox in bboxes[i]:\n",
    "    plt.gca().add_patch(matplotlib.patches.Rectangle((bbox[0], bbox[1]), bbox[2], bbox[3], lw = 2, ec = 'r', fc = 'none'))\n",
    "    # patches.Rectangle((x, y), w, h, linewidth, edgecolor, facecolor)\n",
    "plt.savefig(\"single-rectangle_data.png\", dpi = 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((50000, 64), 2.8974600496667334e-17, 0.9999999999999992)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reshape and normalize the image data to mean 0 and std 1. \n",
    "X = (imgs.reshape(num_imgs, -1) - np.mean(imgs)) / np.std(imgs)\n",
    "X.shape, np.mean(X), np.std(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((50000, 4), 0.28125625, 0.17569304720431456)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Normalize x, y, w, h by img_size, so that all values are between 0 and 1.\n",
    "# Important: Do not shift to negative values (e.g. by setting to mean 0), because the IOU calculation needs positive w and h.\n",
    "y = bboxes.reshape(num_imgs, -1) / img_size\n",
    "y.shape, np.mean(y), np.std(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split training and test.\n",
    "i = int(0.8 * num_imgs)\n",
    "train_X, test_X = X[:i], X[i:]\n",
    "train_y ,test_y = y[:i], y[i:]\n",
    "test_imgs = imgs[i:]\n",
    "test_bboxes = bboxes[i:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_2 (Dense)              (None, 200)               13000     \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 4)                 804       \n",
      "=================================================================\n",
      "Total params: 13,804\n",
      "Trainable params: 13,804\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Build the model.\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "model = Sequential([\n",
    "        Dense(200, input_dim = X.shape[-1]),\n",
    "        Activation('relu'), \n",
    "        Dropout(0.2), \n",
    "        Dense(y.shape[-1])\n",
    "        ])\n",
    "model.compile(loss = 'mse', optimizer = 'adam', metrics = ['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1250/1250 [==============================] - 1s 818us/step - loss: 0.0254 - accuracy: 0.7064 - val_loss: 7.2042e-04 - val_accuracy: 0.8473\n",
      "Epoch 2/30\n",
      "1250/1250 [==============================] - 1s 805us/step - loss: 0.0023 - accuracy: 0.8432 - val_loss: 2.8021e-04 - val_accuracy: 0.8604\n",
      "Epoch 3/30\n",
      "1250/1250 [==============================] - 1s 792us/step - loss: 0.0013 - accuracy: 0.8493 - val_loss: 1.8308e-04 - val_accuracy: 0.8783\n",
      "Epoch 4/30\n",
      "1250/1250 [==============================] - 1s 784us/step - loss: 0.0011 - accuracy: 0.8512 - val_loss: 1.3888e-04 - val_accuracy: 0.8294\n",
      "Epoch 5/30\n",
      "1250/1250 [==============================] - 1s 783us/step - loss: 9.4208e-04 - accuracy: 0.8489 - val_loss: 1.3862e-04 - val_accuracy: 0.8701\n",
      "Epoch 6/30\n",
      "1250/1250 [==============================] - 1s 786us/step - loss: 8.7218e-04 - accuracy: 0.8492 - val_loss: 1.7206e-04 - val_accuracy: 0.8562\n",
      "Epoch 7/30\n",
      "1250/1250 [==============================] - 1s 836us/step - loss: 8.0919e-04 - accuracy: 0.8490 - val_loss: 1.5395e-04 - val_accuracy: 0.8606\n",
      "Epoch 8/30\n",
      "1250/1250 [==============================] - 1s 780us/step - loss: 7.6963e-04 - accuracy: 0.8504 - val_loss: 2.0210e-04 - val_accuracy: 0.8576\n",
      "Epoch 9/30\n",
      "1250/1250 [==============================] - 1s 788us/step - loss: 7.3686e-04 - accuracy: 0.8497 - val_loss: 1.4811e-04 - val_accuracy: 0.8521\n",
      "Epoch 10/30\n",
      "1250/1250 [==============================] - 1s 778us/step - loss: 7.1224e-04 - accuracy: 0.8489 - val_loss: 1.2180e-04 - val_accuracy: 0.8246\n",
      "Epoch 11/30\n",
      "1250/1250 [==============================] - 1s 851us/step - loss: 6.8142e-04 - accuracy: 0.8490 - val_loss: 1.7299e-04 - val_accuracy: 0.8686\n",
      "Epoch 12/30\n",
      "1250/1250 [==============================] - 1s 845us/step - loss: 6.6628e-04 - accuracy: 0.8486 - val_loss: 1.8113e-04 - val_accuracy: 0.7997\n",
      "Epoch 13/30\n",
      "1250/1250 [==============================] - 1s 822us/step - loss: 6.6041e-04 - accuracy: 0.8495 - val_loss: 1.6292e-04 - val_accuracy: 0.8301\n",
      "Epoch 14/30\n",
      "1250/1250 [==============================] - 1s 808us/step - loss: 6.4669e-04 - accuracy: 0.8498 - val_loss: 1.1962e-04 - val_accuracy: 0.8607\n",
      "Epoch 15/30\n",
      "1250/1250 [==============================] - 1s 824us/step - loss: 6.4032e-04 - accuracy: 0.8491 - val_loss: 1.3155e-04 - val_accuracy: 0.8784\n",
      "Epoch 16/30\n",
      "1250/1250 [==============================] - 1s 906us/step - loss: 6.2867e-04 - accuracy: 0.8483 - val_loss: 1.3925e-04 - val_accuracy: 0.8704\n",
      "Epoch 17/30\n",
      "1250/1250 [==============================] - 1s 805us/step - loss: 6.3173e-04 - accuracy: 0.8471 - val_loss: 1.5792e-04 - val_accuracy: 0.8961\n",
      "Epoch 18/30\n",
      "1250/1250 [==============================] - 1s 798us/step - loss: 6.2736e-04 - accuracy: 0.8492 - val_loss: 1.8473e-04 - val_accuracy: 0.9034\n",
      "Epoch 19/30\n",
      "1250/1250 [==============================] - 1s 802us/step - loss: 6.2004e-04 - accuracy: 0.8475 - val_loss: 1.4763e-04 - val_accuracy: 0.8484\n",
      "Epoch 20/30\n",
      "1250/1250 [==============================] - 1s 781us/step - loss: 6.1096e-04 - accuracy: 0.8486 - val_loss: 1.5367e-04 - val_accuracy: 0.8396\n",
      "Epoch 21/30\n",
      "1250/1250 [==============================] - 1s 801us/step - loss: 6.1279e-04 - accuracy: 0.8482 - val_loss: 1.4505e-04 - val_accuracy: 0.9169\n",
      "Epoch 22/30\n",
      "1250/1250 [==============================] - 1s 821us/step - loss: 6.0807e-04 - accuracy: 0.8484 - val_loss: 2.0258e-04 - val_accuracy: 0.7910\n",
      "Epoch 23/30\n",
      "1250/1250 [==============================] - 1s 801us/step - loss: 6.0697e-04 - accuracy: 0.8485 - val_loss: 1.6725e-04 - val_accuracy: 0.8531\n",
      "Epoch 24/30\n",
      "1250/1250 [==============================] - 1s 817us/step - loss: 6.0674e-04 - accuracy: 0.8469 - val_loss: 1.6547e-04 - val_accuracy: 0.8252\n",
      "Epoch 25/30\n",
      "1250/1250 [==============================] - 1s 812us/step - loss: 6.0036e-04 - accuracy: 0.8486 - val_loss: 1.2866e-04 - val_accuracy: 0.8477\n",
      "Epoch 26/30\n",
      "1250/1250 [==============================] - 1s 796us/step - loss: 5.9939e-04 - accuracy: 0.8487 - val_loss: 9.9427e-05 - val_accuracy: 0.8228\n",
      "Epoch 27/30\n",
      "1250/1250 [==============================] - 1s 854us/step - loss: 6.0053e-04 - accuracy: 0.8472 - val_loss: 1.3103e-04 - val_accuracy: 0.8664\n",
      "Epoch 28/30\n",
      "1250/1250 [==============================] - 1s 811us/step - loss: 5.8815e-04 - accuracy: 0.8479 - val_loss: 1.7881e-04 - val_accuracy: 0.8438\n",
      "Epoch 29/30\n",
      "1250/1250 [==============================] - 1s 767us/step - loss: 5.9304e-04 - accuracy: 0.8482 - val_loss: 1.6061e-04 - val_accuracy: 0.8202\n",
      "Epoch 30/30\n",
      "1250/1250 [==============================] - 1s 815us/step - loss: 5.9003e-04 - accuracy: 0.8484 - val_loss: 9.8920e-05 - val_accuracy: 0.8060\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2c653d6e6a0>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train\n",
    "model.fit(train_X, train_y, epochs = 30, validation_data = (test_X, test_y), verbose = 1,\n",
    "          callbacks = [ModelCheckpoint('Single_Rectangle_model.h5',\n",
    "                                       monitor = 'val_accuracy',\n",
    "                                       save_best_only = True)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 1, 4)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predict bounding boxes on the test images.\n",
    "from keras.models import load_model\n",
    "model_test = load_model('Single_Rectangle_model.h5')\n",
    "prediction = model_test.predict(test_X)\n",
    "pred_bboxes = prediction * img_size\n",
    "pred_bboxes = pred_bboxes.reshape(len(pred_bboxes), num_objects, -1)\n",
    "pred_bboxes.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IoU Calculating Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def IOU(bbox1, bbox2):\n",
    "    '''Calculate overlap between two bounding boxes [x, y, w, h] as the area of intersection over the area of unity'''\n",
    "    x1, y1, w1, h1 = bbox1[0], bbox1[1], bbox1[2], bbox1[3]\n",
    "    x2, y2, w2, h2 = bbox2[0], bbox2[1], bbox2[2], bbox2[3]\n",
    "\n",
    "    w_I = min(x1 + w1, x2 + w2) - max(x1, x2)\n",
    "    h_I = min(y1 + h1, y2 + h2) - max(y1, y2)\n",
    "    if w_I <= 0 or h_I <= 0:  # no overlap\n",
    "        return 0.\n",
    "    I = w_I * h_I\n",
    "\n",
    "    U = w1 * h1 + w2 * h2 - I\n",
    "\n",
    "    return I / U"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x216 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Show a few images and predicted bounding boxes from the test dataset. \n",
    "plt.figure(figsize = (12, 3))\n",
    "for i_subplot in range(1, 5):\n",
    "    plt.subplot(1, 4, i_subplot)\n",
    "    i = np.random.randint(len(test_imgs))\n",
    "    plt.imshow(test_imgs[i].T, cmap = 'Greys', interpolation = 'none', origin = 'lower', extent = [0, img_size, 0, img_size])\n",
    "    for pred_bbox, exp_bbox in zip(pred_bboxes[i], test_bboxes[i]):\n",
    "        plt.gca().add_patch(matplotlib.patches.Rectangle((pred_bbox[0], pred_bbox[1]), pred_bbox[2], pred_bbox[3], lw = 2, ec = 'r', fc = 'none'))\n",
    "        plt.annotate(\"IOU: {:.2f}\".format(IOU(pred_bbox, exp_bbox)), (pred_bbox[0], pred_bbox[1] + pred_bbox[3] + 0.2), color = 'r')\n",
    "        # plt.annotate(text, (x, y), color)\n",
    "        \n",
    "plt.savefig(\"single-rectangle_prediction.png\", dpi = 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overall Assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8225096374149633"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate the mean IOU (overlap) between the predicted and expected bounding boxes on the test dataset. \n",
    "summed_IOU = 0.\n",
    "for pred_bbox, test_bbox in zip(pred_bboxes.reshape(-1, 4), test_bboxes.reshape(-1, 4)):\n",
    "    summed_IOU += IOU(pred_bbox, test_bbox)\n",
    "mean_IOU = summed_IOU / len(pred_bboxes)\n",
    "mean_IOU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
